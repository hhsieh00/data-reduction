{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:19:23) \n",
      "[GCC Clang 10.0.1 ]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "sys.path.append('/Users/hhsieh/anaconda3/envs/astroconda/lib/python3.6/site-packages')\n",
    "sys.path.append('/opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages')\n",
    "print(sys.version)\n",
    "from astropy.io import fits\n",
    "from astropy.io.fits import getheader\n",
    "from astropy.modeling import models\n",
    "from astropy import nddata\n",
    "from astropy import units as u\n",
    "import astropy.units as u\n",
    "import astropy.coordinates as coord\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord,Angle\n",
    "from astroquery.jplhorizons import Horizons\n",
    "import ccdproc as cp\n",
    "from ccdproc import CCDData, ImageFileCollection\n",
    "import numpy as np\n",
    "import math, glob, os, bz2, subprocess, sys\n",
    "import cosmics_py3\n",
    "import scipy.signal as signal\n",
    "import scipy.ndimage as ndimage\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def compress_file_fpack(filename):\n",
    "    fpack_command  = '/Users/hhsieh/Astro/tools/cfitsio/fpack'\n",
    "    delete_command = '/bin/rm'\n",
    "    fpack_cmd = [fpack_command,filename]\n",
    "    process = subprocess.call(fpack_cmd)\n",
    "    if process == 0:\n",
    "        delete_cmd = [delete_command,filename]\n",
    "        process = subprocess.call(delete_cmd)\n",
    "    else:\n",
    "        print('fpack command failed.')\n",
    "    return None\n",
    "\n",
    "def decompress_file_fpack(filename):\n",
    "    funpack_command = '/Users/hhsieh/Astro/tools/cfitsio/funpack'\n",
    "    delete_command  = '/bin/rm'\n",
    "    funpack_cmd = [funpack_command,filename]\n",
    "    process = subprocess.call(funpack_cmd)\n",
    "    if process == 0:\n",
    "        delete_cmd = [delete_command,filename]\n",
    "        process = subprocess.call(delete_cmd)\n",
    "    else:\n",
    "        print('funpack command failed.')\n",
    "    return None\n",
    "\n",
    "def convert_to_long_target_desig(short_desig):\n",
    "    long_desig = short_desig\n",
    "    if short_desig == '133P':        long_desig = '133P/1996 N2 (Elst-Pizarro 1)'\n",
    "    if short_desig == '176P':        long_desig = '176P/1999 RE70 (LINEAR 52)'\n",
    "    if short_desig == '233P':        long_desig = '233P/2005 JR71 (La Sagra)'\n",
    "    if short_desig == '238P':        long_desig = '238P/2005 U1 (Read 3)'\n",
    "    if short_desig == '259P':        long_desig = '259P/2008 R1 (Garradd 4)'\n",
    "    if short_desig == '2006 VW139':  long_desig = '288P/2006 VW139 (300163)'\n",
    "    if short_desig == '288P':        long_desig = '288P/2006 VW139 (300163)'\n",
    "    if short_desig == '313P':        long_desig = '313P/2014 S4 (Gibbs 16)'\n",
    "    if short_desig == 'P/2010 R2':   long_desig = '324P/2010 R2 (La Sagra 4)'\n",
    "    if short_desig == '324P':        long_desig = '324P/2010 R2 (La Sagra 4)'\n",
    "    if short_desig == '358P':        long_desig = '358P/2012 T1 (PanSTARRS 11)'\n",
    "    if short_desig == 'P/2012 T1':   long_desig = '358P/2012 T1 (PanSTARRS 11)'\n",
    "    if short_desig == 'P/2013 P5':   long_desig = '311P/2013 P5 (PanSTARRS)'\n",
    "    if short_desig == '2013 P5':     long_desig = '311P/2013 P5 (PanSTARRS)'\n",
    "    if short_desig == '197P':        long_desig = '197P/2003 KV2 (LINEAR 30)'\n",
    "    if short_desig == 'P/2016 J1-A': long_desig = 'P/2016 J1-A (PANSTARRS)'\n",
    "    if short_desig == 'P/2015 X6':   long_desig = 'P/2015 X6 (PANSTARRS)'\n",
    "    return long_desig\n",
    "\n",
    "#def convert_to_short_target_desig(long_desig):\n",
    "#    short_desig = long_desig\n",
    "#    if long_desig == '133P/1996 N2 (Elst-Pizarro 1)': short_desig = '133P'\n",
    "#    if long_desig == '176P/1999 RE70 (LINEAR 52)':    short_desig = '176P'\n",
    "#    if long_desig == '238P/2005 U1 (Read 3)':         short_desig = '238P'\n",
    "#    if long_desig == '259P/2008 R1 (Garradd 4)':      short_desig = '259P'\n",
    "#    if long_desig == '288P/2006 VW139 (300163)':      short_desig = '288P'\n",
    "#    if long_desig == '313P/2014 S4 (Gibbs 16)':       short_desig = '313P'\n",
    "#    if long_desig == '324P/2010 R2 (La Sagra 4)':     short_desig = '324P'\n",
    "#    if long_desig == '358P/2012 T1 (PanSTARRS 11)':   short_desig = '358P'\n",
    "#    return long_desig\n",
    "\n",
    "\n",
    "#def query_horizons(object_id,obs_code,obs_datetime,time_step):\n",
    "#    # Create and execute JPL Horizons query for a given object, observatory code, date, and time step\n",
    "#    date_start = Time('{:s}'.format(obs_datetime),scale='utc',format='iso')\n",
    "#    dt = TimeDelta(1,format='jd')\n",
    "#    date_end = date_start+1\n",
    "#    obj = Horizons(id=object_id, location=obs_code,epochs={'start':date_start.iso,'stop':date_end.iso,'step':time_step})\n",
    "#    ephems = obj.ephemerides()\n",
    "#    return ephems\n",
    "\n",
    "def get_geometry_params(object_name,obs_date,obs_time,exp_time):\n",
    "    obs_code  = '500'   # observatory code\n",
    "    time_step = '2d'\n",
    "    date_start = Time('{:s} {:s}'.format(obs_date,obs_time),scale='utc',format='iso')\n",
    "    mid_dt = TimeDelta(exp_time,format='sec') / 2\n",
    "    date_mid = date_start + mid_dt\n",
    "    #date_next = date_mid + 1\n",
    "    date_next = date_start + 1\n",
    "    #print(date_mid.jd)\n",
    "    #obj = Horizons(id=object_name,location=obs_code,epochs={'start':date_mid.iso,'stop':date_next.iso,'step':time_step})\n",
    "    obj = Horizons(id=object_name,location=obs_code,epochs=date_mid.jd)\n",
    "    #print(object_name,obs_code,date_mid.iso,date_next.iso,time_step)\n",
    "    #print(object_name,obs_code,date_mid.jd)\n",
    "    #print(obj)\n",
    "    ephems = obj.ephemerides()\n",
    "    #print(ephems.columns)\n",
    "    ra = ephems[0]['RA']\n",
    "    dec = ephems[0]['DEC']\n",
    "    ra_rate = ephems[0]['RA_rate']\n",
    "    dec_rate = ephems[0]['DEC_rate']\n",
    "    heliodist = ephems[0]['r']\n",
    "    geodist   = ephems[0]['delta']\n",
    "    phsang    = ephems[0]['alpha']\n",
    "    antisolarPA = ephems[0]['sunTargetPA']\n",
    "    neghelioPA  = ephems[0]['velocityPA']\n",
    "    trueanom    = ephems[0]['true_anom']\n",
    "    ra_angle = Angle(ra * u.deg)\n",
    "    dec_angle = Angle(dec * u.deg)\n",
    "    ra_hms = ra_angle.to_string(unit=u.hour,sep=':',precision=1,pad=True)\n",
    "    dec_dms = dec_angle.to_string(unit=u.degree,sep=':',precision=0,pad=True)\n",
    "    \n",
    "    return ra_hms,dec_dms,ra_rate,dec_rate,heliodist,geodist,phsang,antisolarPA,neghelioPA,trueanom\n",
    "    \n",
    "\n",
    "#def retrieve_nightly_ephems(object_id,obs_code,obs_datetime,time_step_min):\n",
    "#    # Sends a query to JPL Horizons for a given object, observatory code, date, and time step,\n",
    "#    #   and outputs date/time, RA, and Dec to an astropy Table\n",
    "#    time_step = '{:d}m'.format(time_step_min)\n",
    "#    ephems = query_horizons(object_id,obs_code,obs_datetime,time_step)\n",
    "#    num_lines_all = len(ephems)\n",
    "#    num_lines     = 0\n",
    "#    \n",
    "#    # Count ephemeris entries that meet night-time (or astronomical twilight) and airmass requirements\n",
    "#    for idx in range(0,num_lines_all):\n",
    "#        if (ephems[idx]['solar_presence'] == '' or ephems[idx]['solar_presence'] == 'A') and ephems[idx]['airmass'] < 2.5:\n",
    "#            num_lines += 1\n",
    "#    \n",
    "#    # Initialize ephemeris arrays\n",
    "#    eph_datetime_str = [0 for idx in range(num_lines)]\n",
    "#    eph_ra           = [0 for idx in range(num_lines)]\n",
    "#    eph_dec          = [0 for idx in range(num_lines)]\n",
    "#\n",
    "#    # Save ephemeris entries that meet night-time (or astronomical twilight) and airmass requirements\n",
    "#    idx2 = 0\n",
    "#    for idx1 in range(0,num_lines_all):\n",
    "#        if (ephems[idx1]['solar_presence'] == '' or ephems[idx1]['solar_presence'] == 'A') and ephems[idx1]['airmass'] < 2.5:\n",
    "#            eph_datetime_str[idx2] = ephems[idx1]['datetime_str']\n",
    "#            eph_ra[idx2]           = ephems[idx1]['RA']\n",
    "#            eph_dec[idx2]          = ephems[idx1]['DEC']\n",
    "#            idx2 += 1\n",
    "#\n",
    "#    # Create ephemeris table for entries that meet night-time (or astronomical twilight) and airmass requirements\n",
    "#    ephem_table = Table()\n",
    "#    ephem_table = Table([eph_datetime_str,eph_ra,eph_dec],names=('datetime','ra','dec'),dtype=('S17','f8','f8'))\n",
    "#    ephem_table['clear'] = True\n",
    "#\n",
    "#    # Confirm start and end times and positions of object when it is observable\n",
    "#    print('Start time and position: {:s} {:f} {:f}'.format(ephem_table[0]['datetime'],ephem_table[0]['ra'],ephem_table[0]['dec']))\n",
    "#    print('End time and position:   {:s} {:f} {:f}'.format(ephem_table[len(ephem_table)-1]['datetime'],ephem_table[len(ephem_table)-1]['ra'],ephem_table[len(ephem_table)-1]['dec']))\n",
    "#    \n",
    "#    return ephem_table\n",
    "\n",
    "def update_metadata(fits_file):\n",
    "    with fits.open(fits_file) as hdulist:\n",
    "        data = hdulist[0].data\n",
    "        hdr = hdulist[0].header\n",
    "    \n",
    "    # Insert full object designation header field\n",
    "    object_name = hdr['OBJECT']\n",
    "    object_desig = convert_to_long_target_desig(object_name)\n",
    "    hdr['OBJDESIG'] = (object_desig,'Full object designation')\n",
    "\n",
    "    # Shift azimuth from -180-to-180 scale to 0-to-360 scale\n",
    "    azimuth = hdr['AZIMUTH']\n",
    "    if azimuth < 0: hdr['AZIMUTH'] = azimuth + 360\n",
    "    \n",
    "    # Add additional keywords if not present\n",
    "    if 'ORIGIN'   not in hdr: hdr['ORIGIN']   = ('N/A','FITS file originator')\n",
    "    if 'IRAF-TLM' not in hdr: hdr['IRAF-TLM'] = ('N/A','Time of last modification')\n",
    "    \n",
    "    # Ensure all images have both OIWFS and PWFS2 guider information\n",
    "    if 'OIARA'    not in hdr: hdr['OIARA']    = ('N/A','RA of OIWFS guide star')\n",
    "    if 'OIARV'    not in hdr: hdr['OIARV']    = ('N/A','OIWFS Heliocentric Radial Velocity')\n",
    "    if 'OIAWAVEL' not in hdr: hdr['OIAWAVEL'] = ('N/A','OIWFS Effective Target Wavelength')\n",
    "    if 'OIADEC'   not in hdr: hdr['OIADEC']   = ('N/A','Declination of OIWFS guide star')\n",
    "    if 'OIAEPOCH' not in hdr: hdr['OIAEPOCH'] = ('N/A','Epoch for OIWFS guide star coordinates')\n",
    "    if 'OIAEQUIN' not in hdr: hdr['OIAEQUIN'] = ('N/A','Equinox for OIWFS guide star coordinates')\n",
    "    if 'OIAFRAME' not in hdr: hdr['OIAFRAME'] = ('N/A','OIWFS Target co-ordinate system')\n",
    "    if 'OIAOBJEC' not in hdr: hdr['OIAOBJEC'] = ('N/A','Object Name for OIWFS, Chop A')\n",
    "    if 'OIAPMDEC' not in hdr: hdr['OIAPMDEC'] = ('N/A','OIWFS Proper Motion in Declination')\n",
    "    if 'OIAPMRA'  not in hdr: hdr['OIAPMRA']  = ('N/A','OIWFS Proper Motion in RA')\n",
    "    if 'OIAPARAL' not in hdr: hdr['OIAPARAL'] = ('N/A','OIWFS Parallax of Target')\n",
    "    if 'OIFREQ'   not in hdr: hdr['OIFREQ']   = ('N/A','OIWFS sampling frequency (Hz)')\n",
    "\n",
    "    if 'P2ARA'    not in hdr: hdr['P2ARA']    = ('N/A','RA of PWFS2 guide star')\n",
    "    if 'P2ARV'    not in hdr: hdr['P2ARV']    = ('N/A','PWFS2 Heliocentric Radial Velocity')\n",
    "    if 'P2AWAVEL' not in hdr: hdr['P2AWAVEL'] = ('N/A','PWFS2 Effective Target Wavelength')\n",
    "    if 'P2ADEC'   not in hdr: hdr['P2ADEC']   = ('N/A','Declination of PWFS2 guide star')\n",
    "    if 'P2AEPOCH' not in hdr: hdr['P2AEPOCH'] = ('N/A','Epoch for PWFS2 guide star coordinates')\n",
    "    if 'P2AEQUIN' not in hdr: hdr['P2AEQUIN'] = ('N/A','Equinox for PWFS2 guide star coordinates')\n",
    "    if 'P2AFRAME' not in hdr: hdr['P2AFRAME'] = ('N/A','PWFS2 Target co-ordinate system')\n",
    "    if 'P2AOBJEC' not in hdr: hdr['P2AOBJEC'] = ('N/A','Object Name for PWFS 2, Chop A')\n",
    "    if 'P2APMDEC' not in hdr: hdr['P2APMDEC'] = ('N/A','PWFS2 Proper Motion in Declination')\n",
    "    if 'P2APMRA'  not in hdr: hdr['P2APMRA']  = ('N/A','PWFS2 Proper Motion in RA')\n",
    "    if 'P2APARAL' not in hdr: hdr['P2APARAL'] = ('N/A','PWFS2 Parallax of Target')\n",
    "    if 'P2FOCUS'  not in hdr: hdr['P2FOCUS']  = ('N/A','PWFS2 Focus Offset (mm)')\n",
    "    if 'P2FREQ'   not in hdr: hdr['P2FREQ']   = ('N/A','PWFS2 sampling frequency (Hz)')\n",
    "    \n",
    "    if 'P1ARA'    not in hdr: hdr['P1ARA']    = ('N/A','RA of PWFS1 guide star')\n",
    "    if 'P1ARV'    not in hdr: hdr['P1ARV']    = ('N/A','PWFS1 Heliocentric Radial Velocity')\n",
    "    if 'P1AWAVEL' not in hdr: hdr['P1AWAVEL'] = ('N/A','PWFS1 Effective Target Wavelength')\n",
    "    if 'P1ADEC'   not in hdr: hdr['P1ADEC']   = ('N/A','Declination of PWFS1 guide star')\n",
    "    if 'P1AEPOCH' not in hdr: hdr['P1AEPOCH'] = ('N/A','Epoch for PWFS1 guide star coordinates')\n",
    "    if 'P1AEQUIN' not in hdr: hdr['P1AEQUIN'] = ('N/A','Equinox for PWFS1 guide star coordinates')\n",
    "    if 'P1AFRAME' not in hdr: hdr['P1AFRAME'] = ('N/A','PWFS1 Target co-ordinate system')\n",
    "    if 'P1AOBJEC' not in hdr: hdr['P1AOBJEC'] = ('N/A','Object Name for PWFS 1, Chop A')\n",
    "    if 'P1APMDEC' not in hdr: hdr['P1APMDEC'] = ('N/A','PWFS1 Proper Motion in Declination')\n",
    "    if 'P1APMRA'  not in hdr: hdr['P1APMRA']  = ('N/A','PWFS1 Proper Motion in RA')\n",
    "    if 'P1APARAL' not in hdr: hdr['P1APARAL'] = ('N/A','PWFS1 Parallax of Target')\n",
    "    if 'P1FOCUS'  not in hdr: hdr['P1FOCUS']  = ('N/A','PWFS1 Focus Offset (mm)')\n",
    "    if 'P1FREQ'   not in hdr: hdr['P1FREQ']   = ('N/A','PWFS1 sampling frequency (Hz)')\n",
    "\n",
    "    # Ensure all images have pause-related header keywords\n",
    "    if 'EXPPAU00' not in hdr: hdr['EXPPAU00'] = ('N/A','UT pause')\n",
    "    if 'EXPRES00' not in hdr: hdr['EXPRES00'] = ('N/A','UT of continue')\n",
    "\n",
    "    # Ensure all images contain maximum number of bias file slots\n",
    "    if 'BIAS_2' not in hdr: hdr['BIAS_2'] = ('N/A','2nd bias frame used')\n",
    "    if 'BIAS_3' not in hdr: hdr['BIAS_3'] = ('N/A','3rd bias frame used')\n",
    "    if 'BIAS_4' not in hdr: hdr['BIAS_4'] = ('N/A','4th bias frame used')\n",
    "    \n",
    "    if hdr['BIAS_2'] == 'n/a': hdr['BIAS_2'] = 'N/A'\n",
    "    if hdr['BIAS_3'] == 'n/a': hdr['BIAS_3'] = 'N/A'\n",
    "    if hdr['BIAS_4'] == 'n/a': hdr['BIAS_4'] = 'N/A'\n",
    "\n",
    "    # Add requested timing window keywords if not present\n",
    "    if 'REQTWS01' not in hdr: hdr['REQTWS01'] = ('N/A','Requested Timing Window 01 Start (UTC)')\n",
    "    if 'REQTWD01' not in hdr: hdr['REQTWD01'] = ('N/A','Requested Timing Window 01 Duration [seconds]')\n",
    "    if 'REQTWN01' not in hdr: hdr['REQTWN01'] = ('N/A','Requested Timing Window 01 Number of Repeats')\n",
    "    if 'REQTWP01' not in hdr: hdr['REQTWP01'] = ('N/A','Requested Timing Window 01 Repeat Period [secon')\n",
    "    \n",
    "    # Update comments on reduction status keywords\n",
    "    hdr['OSCANSUB'] = (hdr['OSCANSUB'],'Overscan subtraction performed? (T/F)')\n",
    "    hdr['TRIMMED']  = (hdr['TRIMMED'],'Image trimming performed? (T/F)')\n",
    "    hdr['ZEROCORR'] = (hdr['ZEROCORR'],'Bias subtraction performed? (T/F)')\n",
    "    hdr['FLATCORR'] = (hdr['FLATCORR'],'Flatfield correction performed? (T/F)')\n",
    "    hdr['CRCORR']   = (True,'Cosmic ray removal performed? (T/F)')\n",
    "    hdr['RADESYSA'] = (hdr['RADESYSA'],'Equatorial coordinate system')\n",
    "    hdr['BUNIT']    = (hdr['BUNIT'],'Unit of original pixel value')\n",
    "    \n",
    "    # Remove checksums\n",
    "    if 'CHECKSUM' in hdr: del hdr['CHECKSUM']\n",
    "    if 'DATASUM'  in hdr: del hdr['DATASUM']\n",
    "        \n",
    "    fits.writeto(fits_file,data,hdr,overwrite=True,checksum=True)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_metadata(fits_file):\n",
    "    object_name,object_desig,obs_date,obs_time,exp_time,filter_name,obs_class = '','','','','','',''\n",
    "\n",
    "    with fits.open(fits_file) as hdulist:\n",
    "        data = hdulist[0].data\n",
    "        hdr = hdulist[0].header\n",
    "        \n",
    "    object_name = hdr['OBJECT']\n",
    "    obs_date    = hdr['DATE']\n",
    "    obs_time    = hdr['UTSTART'][:10]\n",
    "    exp_time    = hdr['EXPTIME']\n",
    "    filter_name = hdr['FILTER2'][:1]\n",
    "    object_desig = hdr['OBJDESIG']\n",
    "    obs_class = hdr['OBSCLASS'].strip()\n",
    "    #date_start  = Time('{:s} {:s}'.format(obs_date,utstart),scale='utc',format='iso')\n",
    "    #obs_time    = date_start.iso[:10]\n",
    "    #print(obs_time)\n",
    "    \n",
    "    #object_desig = convert_to_long_target_desig(object_name)\n",
    "    #hdr['OBJDESIG'] = (object_desig,'Full object designation')\n",
    "    #exp_time = int(round(elapsed))\n",
    "    #hdr['EXPTIME'] = exp_time\n",
    "    \n",
    "    return object_name,object_desig,obs_date,obs_time,exp_time,filter_name,obs_class\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update_object_info(base_dir):\n",
    "    print('{:s} - Starting processing data in {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),base_dir))\n",
    "    dir_procfits = 'flatfits_pyt'\n",
    "    \n",
    "    #if base_dir[-6:-1] == 'LP-11':  output_file  = base_dir + 'target_table_' + base_dir[-15:-1] + '.txt'\n",
    "    #if base_dir[-7:-1] == 'LP-104': output_file  = base_dir + 'target_table_' + base_dir[-16:-1] + '.txt'\n",
    "    \n",
    "    if base_dir[-28:-17] == 'gemini_data': output_file = base_dir + 'target_table_' + base_dir[-16:-1] + '.txt' # for Q-64\n",
    "    if base_dir[-27:-16] == 'gemini_data': output_file = base_dir + 'target_table_' + base_dir[-15:-1] + '.txt' # for LP-11\n",
    "    if base_dir[-26:-15] == 'gemini_data': output_file = base_dir + 'target_table_' + base_dir[-14:-1] + '.txt' # for Q-64\n",
    "    \n",
    "    #output_file  = base_dir + 'target_table_' + base_dir[-16:-1] + '.txt' # for LP-104\n",
    "    #output_file  = base_dir + 'target_table_' + base_dir[-15:-1] + '.txt' # for LP-11\n",
    "    #output_file  = base_dir + 'target_table_' + base_dir[-14:-1] + '.txt' # for Q-64\n",
    "\n",
    "    with open(output_file,'w') as of:\n",
    "        #of.write('File Name      Telescope    Target       LongDesig                        ObsDate    ObsStartTime    ExpTime  Filter     RA          Dec     RA_rate  Dec_rate    r      delta   phsAng  antiSolarPA  helioVelPA  trueAnom\\n')\n",
    "        of.write('File Name      Target       LongDesig                        ObsDate    ObsStartTime    ExpTime  Filter     RA          Dec     RA_rate  Dec_rate    r      delta   phsAng  antiSolarPA  helioVelPA  trueAnom\\n')\n",
    "\n",
    "    os.chdir(base_dir)\n",
    "    for data_dir in sorted(glob.glob('ut*_gemini?')):\n",
    "        path_procfits = base_dir + data_dir + '/' + dir_procfits + '/'\n",
    "    \n",
    "        if data_dir[-1:] == 'N':   instr_id = 'gmosn'\n",
    "        elif data_dir[-1:] == 'S': instr_id = 'gmoss'\n",
    "        else: instr_id = 'not recognized'\n",
    "\n",
    "        if instr_id == 'gmosn' or instr_id == 'gmoss':\n",
    "            if instr_id == 'gmosn': telescope = 'Gemini-N'\n",
    "            if instr_id == 'gmoss': telescope = 'Gemini-S'\n",
    "            if os.path.exists(path_procfits):\n",
    "                os.chdir(path_procfits)\n",
    "                for fz_file in sorted(glob.glob('*.chip2.otzfc.fits.fz')):\n",
    "                    print('{:s} - Processing {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),fz_file[:-3]))\n",
    "\n",
    "                    # Decompress fpacked FITS files\n",
    "                    decompress_file_fpack(fz_file)\n",
    "                    decompress_file_fpack(fz_file[:-15] + '1.otzfc.fits.fz')\n",
    "                    decompress_file_fpack(fz_file[:-15] + '3.otzfc.fits.fz')\n",
    "                \n",
    "                    # Update image headers to ensure PDS compliance\n",
    "                    fits_file = fz_file[:-3]\n",
    "                    update_metadata(fits_file)\n",
    "                    update_metadata(fits_file[:-12] + '1.otzfc.fits')\n",
    "                    update_metadata(fits_file[:-12] + '3.otzfc.fits')\n",
    "                \n",
    "                    # Retrieve image metadata from headers of chip2 files\n",
    "                    object_name,object_desig,obs_date,obs_time,exp_time,filter_name,obs_class = get_metadata(fits_file)\n",
    "                \n",
    "                    # Recompress FITS files\n",
    "                    compress_file_fpack(fits_file)\n",
    "                    compress_file_fpack(fits_file[:-12] + '1.otzfc.fits')\n",
    "                    compress_file_fpack(fits_file[:-12] + '3.otzfc.fits')\n",
    "                \n",
    "                    # Retrieve geometry data for objects in images\n",
    "                    if obs_class == 'science':\n",
    "                        ra_hms,dec_dms,ra_rate,dec_rate,heliodist,geodist,phsang,antisolarPA,neghelioPA,trueanom = get_geometry_params(object_name,obs_date,obs_time,exp_time)\n",
    "                \n",
    "                        # Write metadata and geometry data to output file\n",
    "                        with open(output_file,'a') as of:\n",
    "                            #of.write('{:s}  {:<10s}   {:<11s}  {:<30s}  {:s}   {:s}       {:>4d}     {:s}     {:>8s}  {:>9s}   {:6.1f}   {:6.1f}  {:7.4f}  {:7.4f}   {:4.1f}      {:5.1f}        {:5.1f}      {:5.1f}\\n'.format(fits_file[:13],telescope,object_name,object_desig,obs_date,obs_time,exp_time,filter_name,ra_hms,dec_dms,ra_rate,dec_rate,heliodist,geodist,phsang,antisolarPA,neghelioPA,trueanom))\n",
    "                            of.write('{:s}  {:<11s}  {:<30s}  {:s}   {:s}       {:>4d}     {:s}     {:>8s}  {:>9s}   {:6.1f}   {:6.1f}  {:7.4f}  {:7.4f}   {:4.1f}      {:5.1f}        {:5.1f}      {:5.1f}\\n'.format(fits_file[:13],object_name,object_desig,obs_date,obs_time,int(exp_time),filter_name,ra_hms,dec_dms,ra_rate,dec_rate,heliodist,geodist,phsang,antisolarPA,neghelioPA,trueanom))\n",
    "            else:\n",
    "                print('{:s} - Processed science data directory in {:s} not found.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_dir))\n",
    "        else:\n",
    "            print('{:s} - Directory name format not recognized for {:s}.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_dir))\n",
    "    \n",
    "    print('{:s} - Finished processing data in {:s}.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),base_dir))\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def get_object_info(base_dir):\n",
    "    print('{:s} - Starting processing data in {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),base_dir))\n",
    "    dir_procfits = 'flatfits_pyt'\n",
    "    \n",
    "    #if base_dir[-6:-1] == 'LP-11':  output_file  = base_dir + 'target_table_' + base_dir[-15:-1] + '.txt'\n",
    "    #if base_dir[-7:-1] == 'LP-104': output_file  = base_dir + 'target_table_' + base_dir[-16:-1] + '.txt'\n",
    "    \n",
    "    if base_dir[-28:-17] == 'gemini_data': output_file = base_dir + 'target_table_' + base_dir[-16:-1] + '.txt' # for Q-64\n",
    "    if base_dir[-27:-16] == 'gemini_data': output_file = base_dir + 'target_table_' + base_dir[-15:-1] + '.txt' # for LP-11\n",
    "    if base_dir[-26:-15] == 'gemini_data': output_file = base_dir + 'target_table_' + base_dir[-14:-1] + '.txt' # for Q-64\n",
    "    \n",
    "    #output_file  = base_dir + 'target_table_' + base_dir[-16:-1] + '.txt' # for LP-104\n",
    "    #output_file  = base_dir + 'target_table_' + base_dir[-15:-1] + '.txt' # for LP-11\n",
    "    #output_file  = base_dir + 'target_table_' + base_dir[-14:-1] + '.txt' # for Q-64\n",
    "\n",
    "    with open(output_file,'w') as of:\n",
    "        of.write('File Name      Telescope    Target       LongDesig                        ObsDate    ObsStartTime    ExpTime  Filter     RA          Dec     RA_rate  Dec_rate    r      delta   phsAng  antiSolarPA  helioVelPA  trueAnom\\n')\n",
    "\n",
    "    os.chdir(base_dir)\n",
    "    for data_dir in sorted(glob.glob('ut*_gemini?')):\n",
    "        path_procfits = base_dir + data_dir + '/' + dir_procfits + '/'\n",
    "    \n",
    "        if data_dir[-1:] == 'N':   instr_id = 'gmosn'\n",
    "        elif data_dir[-1:] == 'S': instr_id = 'gmoss'\n",
    "        else: instr_id = 'not recognized'\n",
    "\n",
    "        if instr_id == 'gmosn' or instr_id == 'gmoss':\n",
    "            if instr_id == 'gmosn': telescope = 'Gemini-N'\n",
    "            if instr_id == 'gmoss': telescope = 'Gemini-S'\n",
    "            if os.path.exists(path_procfits):\n",
    "                os.chdir(path_procfits)\n",
    "                for fz_file in sorted(glob.glob('*.chip2.otzfc.fits.fz')):\n",
    "                    print('{:s} - Processing {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),fz_file[:-3]))\n",
    "\n",
    "                    # Decompress fpacked FITS files\n",
    "                    decompress_file_fpack(fz_file)\n",
    "                    fits_file = fz_file[:-3]\n",
    "                \n",
    "                    # Retrieve image metadata from headers of chip2 files\n",
    "                    object_name,object_desig,obs_date,obs_time,exp_time,filter_name,obs_class = get_metadata(fits_file)\n",
    "                \n",
    "                    # Recompress FITS files\n",
    "                    compress_file_fpack(fits_file)\n",
    "                \n",
    "                    # Retrieve geometry data for objects in images\n",
    "                    if obs_class == 'science':\n",
    "                        ra_hms,dec_dms,ra_rate,dec_rate,heliodist,geodist,phsang,antisolarPA,neghelioPA,trueanom = get_geometry_params(object_name,obs_date,obs_time,exp_time)\n",
    "                \n",
    "                        # Write metadata and geometry data to output file\n",
    "                        with open(output_file,'a') as of:\n",
    "                            of.write('{:s}  {:<10s}   {:<11s}  {:<30s}  {:s}   {:s}       {:>4d}     {:s}     {:>8s}  {:>9s}   {:6.1f}   {:6.1f}  {:7.4f}  {:7.4f}   {:4.1f}      {:5.1f}        {:5.1f}      {:5.1f}\\n'.format(fits_file[:13],telescope,object_name,object_desig,obs_date,obs_time,int(exp_time),filter_name,ra_hms,dec_dms,ra_rate,dec_rate,heliodist,geodist,phsang,antisolarPA,neghelioPA,trueanom))\n",
    "            else:\n",
    "                print('{:s} - Processed science data directory in {:s} not found.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_dir))\n",
    "        else:\n",
    "            print('{:s} - Directory name format not recognized for {:s}.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_dir))\n",
    "    \n",
    "    print('{:s} - Finished processing data in {:s}.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),base_dir))\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 12:28:53 - Starting processing data in /volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2022A-LP-104/...\n",
      "2022-06-13 12:28:53 - Processing n20220204.104.chip2.otzfc.fits...\n",
      "2022-06-13 12:28:56 - Processing n20220204.105.chip2.otzfc.fits...\n",
      "2022-06-13 12:28:59 - Processing n20220204.106.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:02 - Processing n20220204.107.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:05 - Processing n20220204.108.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:07 - Processing n20220204.109.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:10 - Processing n20220204.110.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:13 - Processing n20220204.111.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:16 - Processing n20220209.159.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:19 - Processing n20220209.160.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:21 - Processing n20220209.161.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:24 - Processing n20220209.162.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:27 - Processing n20220212.077.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:30 - Processing n20220212.078.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:33 - Processing n20220212.079.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:35 - Processing n20220212.080.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:38 - Processing n20220302.091.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:41 - Processing n20220302.092.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:44 - Processing n20220302.093.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:47 - Processing n20220302.094.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:50 - Processing n20220302.095.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:53 - Processing n20220302.096.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:56 - Processing n20220313.119.chip2.otzfc.fits...\n",
      "2022-06-13 12:29:59 - Processing n20220313.120.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:01 - Processing n20220313.121.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:04 - Processing n20220313.122.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:07 - Processing n20220313.123.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:10 - Processing n20220313.124.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:13 - Processing n20220313.125.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:15 - Processing n20220313.126.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:18 - Processing n20220313.127.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:21 - Processing n20220313.128.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:25 - Processing n20220313.129.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:28 - Processing n20220313.130.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:32 - Processing n20220313.131.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:35 - Processing n20220313.132.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:38 - Processing n20220313.133.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:42 - Processing n20220313.134.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:45 - Processing n20220313.135.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:49 - Processing n20220313.136.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:53 - Processing n20220408.003.chip2.otzfc.fits...\n",
      "2022-06-13 12:30:57 - Processing n20220408.004.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:00 - Processing n20220408.005.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:04 - Processing n20220408.006.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:08 - Processing n20220408.007.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:11 - Processing n20220408.008.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:15 - Processing n20220408.009.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:18 - Processing n20220408.010.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:22 - Processing n20220408.011.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:26 - Processing n20220408.012.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:29 - Processing n20220408.013.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:33 - Processing n20220408.014.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:37 - Processing n20220408.015.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:40 - Processing n20220408.016.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:44 - Processing n20220408.017.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:48 - Processing n20220408.018.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:51 - Processing n20220408.019.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:54 - Processing n20220408.020.chip2.otzfc.fits...\n",
      "2022-06-13 12:31:57 - Processing n20220425.113.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:01 - Processing n20220425.114.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:04 - Processing n20220425.115.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:08 - Processing n20220425.116.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:11 - Processing n20220425.117.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:15 - Processing n20220425.118.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:19 - Processing n20220425.119.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:22 - Processing n20220425.120.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:26 - Processing n20220425.121.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:29 - Processing n20220425.122.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:33 - Processing n20220425.123.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:37 - Processing n20220425.124.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:40 - Processing n20220425.125.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:44 - Processing n20220425.126.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:48 - Processing n20220425.127.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:52 - Processing n20220425.128.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:55 - Processing n20220425.129.chip2.otzfc.fits...\n",
      "2022-06-13 12:32:58 - Processing n20220425.130.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:01 - Processing n20220523.172.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:05 - Processing n20220523.173.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:08 - Processing n20220523.174.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:11 - Processing n20220523.175.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:15 - Processing n20220523.176.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:18 - Processing n20220523.177.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:22 - Processing n20220523.178.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:25 - Processing n20220523.179.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:29 - Processing n20220523.180.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:32 - Processing n20220524.107.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:36 - Processing n20220524.108.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:39 - Processing n20220524.109.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:43 - Processing n20220524.110.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:46 - Processing n20220524.111.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:50 - Processing n20220524.112.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:53 - Processing n20220524.113.chip2.otzfc.fits...\n",
      "2022-06-13 12:33:57 - Processing n20220524.114.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:00 - Processing n20220524.115.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:04 - Processing n20220526.060.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:07 - Processing n20220526.061.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:12 - Processing n20220526.062.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:16 - Processing n20220601.086.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:20 - Processing n20220601.087.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:24 - Processing n20220601.088.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:28 - Processing n20220606.189.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:33 - Processing n20220606.190.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:37 - Processing n20220606.191.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:41 - Finished processing data in /volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2022A-LP-104/.\n",
      "2022-06-13 12:34:41 - Starting processing data in /volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2022A-LP-104/...\n",
      "2022-06-13 12:34:41 - Processing n20220314.202.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:44 - Processing n20220314.203.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:47 - Processing n20220314.204.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:50 - Processing n20220326.033.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:54 - Processing n20220326.034.chip2.otzfc.fits...\n",
      "2022-06-13 12:34:57 - Processing n20220326.035.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:00 - Processing n20220329.102.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:04 - Processing n20220329.103.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:08 - Processing n20220329.104.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:11 - Processing n20220330.187.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:15 - Processing n20220330.188.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:19 - Processing n20220330.189.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:22 - Processing n20220331.099.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:26 - Processing n20220331.100.chip2.otzfc.fits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 12:35:29 - Processing n20220331.101.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:33 - Processing n20220331.102.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:37 - Processing n20220331.153.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:40 - Processing n20220331.154.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:44 - Processing n20220331.155.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:48 - Processing n20220401.068.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:52 - Processing n20220401.069.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:55 - Processing n20220401.070.chip2.otzfc.fits...\n",
      "2022-06-13 12:35:59 - Processing n20220423.046.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:02 - Processing n20220423.047.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:05 - Processing n20220423.048.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:09 - Processing n20220526.044.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:12 - Processing n20220526.045.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:17 - Processing n20220526.046.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:21 - Processing n20220526.132.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:25 - Processing n20220526.133.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:29 - Processing n20220526.134.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:33 - Processing n20220527.103.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:38 - Processing n20220527.104.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:42 - Processing n20220527.105.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:47 - Processing n20220527.106.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:51 - Processing n20220527.143.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:55 - Processing n20220527.144.chip2.otzfc.fits...\n",
      "2022-06-13 12:36:59 - Processing n20220527.145.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:03 - Processing n20220528.017.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:07 - Processing n20220528.018.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:11 - Processing n20220528.019.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:15 - Processing n20220607.120.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:20 - Processing n20220607.121.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:24 - Processing n20220607.122.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:28 - Processing n20220607.155.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:32 - Processing n20220607.156.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:36 - Processing n20220607.157.chip2.otzfc.fits...\n",
      "2022-06-13 12:37:41 - Finished processing data in /volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2022A-LP-104/.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2016B-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2017A-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2017B-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2018A-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2018B-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2019A-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2016B-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2017A-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2017B-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2018A-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2018B-LP-11/')\n",
    "#get_update_object_info('/volumes/Fantom8a/BackupData/gemini/LLP_data/gemini_data.GS-2019B-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom8a/BackupData/gemini/data_queue_programs/gemini_data.GN-2016A-Q-88/')\n",
    "#get_update_object_info('/volumes/Fantom8a/BackupData/gemini/data_queue_programs/gemini_data.GS-2015B-Q-64/')\n",
    "#get_update_object_info('/volumes/Fantom8a/BackupData/gemini/data_queue_programs/gemini_data.GN-2013A-Q-102/')\n",
    "#get_update_object_info('/volumes/Fantom8a/BackupData/gemini/data_queue_programs/gemini_data.GN-2014B-Q-91/')\n",
    "#get_update_object_info('/volumes/Fantom8a/BackupData/gemini/data_queue_programs/gemini_data.GN-2016A-Q-88/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2016B-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2017A-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2017B-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2018A-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2018B-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2019A-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2016B-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2017A-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2017B-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2018A-LP-11/')\n",
    "#get_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2018B-LP-11/')\n",
    "\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2020A-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2020B-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2021A-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2021B-LP-104/')\n",
    "get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GN-2022A-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2019B-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2020A-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2020B-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2021A-LP-104/')\n",
    "#get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2021B-LP-104/')\n",
    "get_update_object_info('/volumes/Fantom12a/BackupData/gemini/data_LLP/gemini_data.GS-2022A-LP-104/')\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
